{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>ERM with DNN under penalty of Equalized Odds</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement here a regular Empirical Risk Minimization (ERM) of a Deep Neural Network (DNN) penalized to enforce an Equalized Odds constraint. More formally, given a dataset of size $n$ consisting of context features $x$, target $y$ and a sensitive information $z$ to protect, we want to solve\n",
    "$$\n",
    "\\text{argmin}_{h\\in\\mathcal{H}}\\frac{1}{n}\\sum_{i=1}^n \\ell(y_i, h(x_i)) + \\lambda \\chi^2|_1\n",
    "$$\n",
    "where $\\ell$ is for instance the MSE and the penalty is\n",
    "$$\n",
    "\\chi^2|_1 = \\left\\lVert\\chi^2\\left(\\hat{\\pi}(h(x)|y, z|y), \\hat{\\pi}(h(x)|y)\\otimes\\hat{\\pi}(z|y)\\right)\\right\\rVert_1\n",
    "$$\n",
    "where $\\hat{\\pi}$ denotes the empirical density estimated through a Gaussian KDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "\n",
    "We use here the _communities and crimes_ dataset that can be found on the UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/datasets/communities+and+crime). Non-predictive information, such as city name, state... have been removed and the file is at the arff format for ease of loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Microsoft VS Code\\PyCodes\\RA_Fairness\\fair_dummies/data/\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('../..')))\n",
    "cur_path = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "sys.path.append(cur_path)\n",
    "base_path = cur_path + '/data/'\n",
    "print(base_path)\n",
    "\n",
    "import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1794,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from examples.data_loading import read_dataset\n",
    "import importlib\n",
    "# importlib.reload(read_dataset)\n",
    "x_train, y_train, z_train, x_test, y_test, z_test = read_dataset(name='crimes', fold=1)\n",
    "n, d = x_train.shape\n",
    "\n",
    "dataset = \"crimes\"\n",
    "seed = 123\n",
    "X, A, Y, X_cal, A_cal, Y_cal, X_test, A_test, Y_test = get_dataset.get_train_test_data(base_path, dataset, seed, dim = 2, specified=\"TotalPctDiv\")\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Deep Neural Network\n",
    "\n",
    "We define a very simple DNN for regression here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NetRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NetRegression, self).__init__()\n",
    "        size = 50\n",
    "        self.first = nn.Linear(input_size, size)\n",
    "        self.fc = nn.Linear(size, size)\n",
    "        self.last = nn.Linear(size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.selu(self.first(x))\n",
    "        out = F.selu(self.fc(out))\n",
    "        out = self.last(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fairness-inducing regularizer\n",
    "We implement now the regularizer. The empirical densities $\\hat{\\pi}$ are estimated using a Gaussian KDE. The L1 functional norm is taken over the values of $y$.\n",
    "$$\n",
    "\\chi^2|_1 = \\left\\lVert\\chi^2\\left(\\hat{\\pi}(x|z, y|z), \\hat{\\pi}(x|z)\\otimes\\hat{\\pi}(y|z)\\right)\\right\\rVert_1\n",
    "$$\n",
    "This used to enforce the conditional independence $X \\perp Y \\,|\\, Z$.\n",
    "Practically, we will want to enforce $\\text{prediction} \\perp \\text{sensitive} \\,|\\, \\text{target}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facl.independence.density_estimation.pytorch_kde import kde\n",
    "from facl.independence.hgr import chi_2_cond\n",
    "\n",
    "def chi_squared_l1_kde(X, Y, Z):\n",
    "    return torch.mean(chi_2_cond(X, Y, Z, kde))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fairness-penalized ERM\n",
    "\n",
    "We now implement the full learning loop. The regression loss used is the quadratic loss with a L2 regularization and the fairness-inducing penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "def regularized_learning(x_train, y_train, z_train, model, fairness_penalty, lr=1e-5, num_epochs=10, penalty=1.0):\n",
    "    # wrap dataset in torch tensors\n",
    "    Y = torch.tensor(y_train.astype(np.float32))\n",
    "    X = torch.tensor(x_train.astype(np.float32))\n",
    "    Z = torch.tensor(z_train.astype(np.float32))\n",
    "    dataset = data_utils.TensorDataset(X, Y, Z)\n",
    "    dataset_loader = data_utils.DataLoader(dataset=dataset, batch_size=200, shuffle=True)\n",
    "\n",
    "    # mse regression objective\n",
    "    data_fitting_loss = nn.MSELoss()\n",
    "\n",
    "    # stochastic optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "\n",
    "    for j in range(num_epochs):\n",
    "        for i, (x, y, z) in enumerate(dataset_loader):\n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x).flatten()\n",
    "                loss = data_fitting_loss(outputs, y)\n",
    "                loss += penalty*fairness_penalty(outputs, z, y)\n",
    "                loss.backward()\n",
    "                return loss\n",
    "\n",
    "            optimizer.step(closure)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "For the evaluation on the test set, we compute two metrics: the MSE (accuracy) and HGR$|_\\infty$ (fairness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facl.independence.hgr import hgr_cond\n",
    "\n",
    "def evaluate(model, x, y, z):\n",
    "    Y = torch.tensor(y.astype(np.float32))\n",
    "    Z = torch.Tensor(z.astype(np.float32))\n",
    "    X = torch.tensor(x.astype(np.float32))\n",
    "\n",
    "    prediction = model(X).detach().flatten()\n",
    "    loss = nn.MSELoss()(prediction, Y)\n",
    "    # hgr_infty = np.max(hgr_cond(prediction, Z, Y, kde))\n",
    "    return loss.item(), 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running everything together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/1000 \n",
      "\t loss: 1.4303, val_loss: 1.3014\n",
      "\n",
      " Epoch 26/1000 \n",
      "\t loss: 1.0061, val_loss: 0.8239\n",
      "\n",
      " Epoch 51/1000 \n",
      "\t loss: 0.9977, val_loss: 0.7856\n",
      "\n",
      " Epoch 76/1000 \n",
      "\t loss: 0.9897, val_loss: 0.7829\n",
      "\n",
      " Epoch 101/1000 \n",
      "\t loss: 0.9951, val_loss: 0.7826\n",
      "\n",
      " Epoch 126/1000 \n",
      "\t loss: 0.9834, val_loss: 0.8131\n",
      "Epoch 129: early stopping\n",
      "###################################################\n",
      "MSE:1.18290958191897\n",
      "Null-MSE:0.960140145461198\n",
      "Fair dummies test (regression score), p-value: 0.000999000999000999\n",
      "\n",
      " Epoch 1/1000 \n",
      "\t loss: 1.3519, val_loss: 1.3349\n",
      "\n",
      " Epoch 26/1000 \n",
      "\t loss: 0.8082, val_loss: 0.8848\n",
      "\n",
      " Epoch 51/1000 \n",
      "\t loss: 0.7968, val_loss: 0.8789\n",
      "\n",
      " Epoch 76/1000 \n",
      "\t loss: 0.7940, val_loss: 0.8645\n",
      "\n",
      " Epoch 101/1000 \n",
      "\t loss: 0.7801, val_loss: 0.8548\n",
      "\n",
      " Epoch 126/1000 \n",
      "\t loss: 0.7739, val_loss: 0.8447\n",
      "\n",
      " Epoch 151/1000 \n",
      "\t loss: 0.7697, val_loss: 0.8509\n",
      "\n",
      " Epoch 176/1000 \n",
      "\t loss: 0.7589, val_loss: 0.8552\n",
      "\n",
      " Epoch 201/1000 \n",
      "\t loss: 0.7955, val_loss: 0.8610\n",
      "Epoch 218: early stopping\n",
      "###################################################\n",
      "MSE:1.5554113317238771\n",
      "Null-MSE:0.9799418914294951\n",
      "Fair dummies test (regression score), p-value: 0.000999000999000999\n",
      "\n",
      " Epoch 1/1000 \n",
      "\t loss: 1.3993, val_loss: 1.3220\n",
      "\n",
      " Epoch 26/1000 \n",
      "\t loss: 0.9440, val_loss: 1.3896\n",
      "\n",
      " Epoch 51/1000 \n",
      "\t loss: 0.9221, val_loss: 1.5205\n",
      "Epoch 54: early stopping\n",
      "###################################################\n",
      "MSE:1.424373595863094\n",
      "Null-MSE:0.9573507776282284\n",
      "Fair dummies test (regression score), p-value: 0.000999000999000999\n",
      "\n",
      " Epoch 1/1000 \n",
      "\t loss: 1.3669, val_loss: 1.4033\n",
      "\n",
      " Epoch 26/1000 \n",
      "\t loss: 0.8345, val_loss: 1.4887\n",
      "\n",
      " Epoch 51/1000 \n",
      "\t loss: 0.8241, val_loss: 1.4999\n",
      "Epoch 54: early stopping\n",
      "###################################################\n",
      "MSE:0.7677324308071056\n",
      "Null-MSE:1.1731415267563687\n",
      "Fair dummies test (regression score), p-value: 0.000999000999000999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Microsoft VS Code\\PyCodes\\RA_Fairness\\fair_dummies\\continuous-fairness-master\\examples\\continuous_fairness_aware_learning\\equalized_odds_dnn.ipynb Cell 15\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Microsoft%20VS%20Code/PyCodes/RA_Fairness/fair_dummies/continuous-fairness-master/examples/continuous_fairness_aware_learning/equalized_odds_dnn.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m20\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Microsoft%20VS%20Code/PyCodes/RA_Fairness/fair_dummies/continuous-fairness-master/examples/continuous_fairness_aware_learning/equalized_odds_dnn.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     X, A, Y, X_cal, A_cal, Y_cal, X_test, A_test, Y_test \u001b[39m=\u001b[39m get_dataset\u001b[39m.\u001b[39mget_train_test_data(base_path, dataset, seed, dim \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, specified\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPctUnemployed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Microsoft%20VS%20Code/PyCodes/RA_Fairness/fair_dummies/continuous-fairness-master/examples/continuous_fairness_aware_learning/equalized_odds_dnn.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     specified_density_te \u001b[39m=\u001b[39m utility_functions\u001b[39m.\u001b[39;49mMAF_density_estimation(np\u001b[39m.\u001b[39;49mconcatenate((Y_cal, Y_test)), np\u001b[39m.\u001b[39;49mconcatenate((A_cal, A_test)), Y_test, A_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Microsoft%20VS%20Code/PyCodes/RA_Fairness/fair_dummies/continuous-fairness-master/examples/continuous_fairness_aware_learning/equalized_odds_dnn.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m##############\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Microsoft%20VS%20Code/PyCodes/RA_Fairness/fair_dummies/continuous-fairness-master/examples/continuous_fairness_aware_learning/equalized_odds_dnn.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     y_perm_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(utility_functions\u001b[39m.\u001b[39mgenerate_X_CPT(\u001b[39m50\u001b[39m,\u001b[39m1000\u001b[39m,specified_density_te))\n",
      "File \u001b[1;32mD:\\Microsoft VS Code\\PyCodes\\RA_Fairness\\fair_dummies\\fair_dummies\\utility_functions.py:261\u001b[0m, in \u001b[0;36mMAF_density_estimation\u001b[1;34m(est_on_Y, est_on_A, Y, A, transform)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mMAF_density_estimation\u001b[39m(est_on_Y, est_on_A, Y, A, transform \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    260\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m transform:\n\u001b[1;32m--> 261\u001b[0m         trained_maf \u001b[39m=\u001b[39m fit_maf([est_on_Y[:,\u001b[39mNone\u001b[39;49;00m], est_on_A])\n\u001b[0;32m    262\u001b[0m         \u001b[39mif\u001b[39;00m Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m2000\u001b[39m:\n\u001b[0;32m    263\u001b[0m             log_lik_mat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([])\n",
      "File \u001b[1;32mD:\\Microsoft VS Code\\PyCodes\\RA_Fairness\\fair_dummies\\fair_dummies\\utility_functions.py:80\u001b[0m, in \u001b[0;36mfit_maf\u001b[1;34m(data, num_mades, hidden_units, activation, n_epochs, n_disp, patience, draw)\u001b[0m\n\u001b[0;32m     78\u001b[0m c_ \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39m(cond_shape,), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m     79\u001b[0m \u001b[39m# log_prob_ = trainable_distribution.log_prob(x_, bijector_kwargs={'conditional_input': c_})\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m log_prob_ \u001b[39m=\u001b[39m maf\u001b[39m.\u001b[39;49mlog_prob(x_, bijector_kwargs\u001b[39m=\u001b[39;49mmake_bijector_kwargs(maf\u001b[39m.\u001b[39;49mbijector, {\u001b[39m'\u001b[39;49m\u001b[39mmaf.\u001b[39;49m\u001b[39m'\u001b[39;49m: {\u001b[39m'\u001b[39;49m\u001b[39mconditional_input\u001b[39;49m\u001b[39m'\u001b[39;49m: c_}}))\n\u001b[0;32m     81\u001b[0m model \u001b[39m=\u001b[39m Model([x_,c_], log_prob_)\n\u001b[0;32m     82\u001b[0m \u001b[39m# the loss function is log likelihood\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:1315\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[1;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[0;32m   1303\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_prob\u001b[39m(\u001b[39mself\u001b[39m, value, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlog_prob\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1304\u001b[0m   \u001b[39m\"\"\"Log probability density/mass function.\u001b[39;00m\n\u001b[0;32m   1305\u001b[0m \n\u001b[0;32m   1306\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[39m      values of type `self.dtype`.\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1315\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_log_prob(value, name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:1297\u001b[0m, in \u001b[0;36mDistribution._call_log_prob\u001b[1;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name_and_control_scope(name, value, kwargs):\n\u001b[0;32m   1296\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_log_prob\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m-> 1297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_prob(value, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1298\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_prob\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m   1299\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mlog(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prob(value, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\transformed_distribution.py:378\u001b[0m, in \u001b[0;36mTransformedDistribution._log_prob\u001b[1;34m(self, y, **kwargs)\u001b[0m\n\u001b[0;32m    374\u001b[0m distribution_kwargs, bijector_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs_split_fn(kwargs)\n\u001b[0;32m    376\u001b[0m \u001b[39m# For caching to work, it is imperative that the bijector is the first to\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[39m# modify the input.\u001b[39;00m\n\u001b[1;32m--> 378\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector\u001b[39m.\u001b[39minverse(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbijector_kwargs)\n\u001b[0;32m    379\u001b[0m event_ndims \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m    380\u001b[0m     ps\u001b[39m.\u001b[39mrank_from_shape,\n\u001b[0;32m    381\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_shape_tensor(),\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevent_shape)\n\u001b[0;32m    384\u001b[0m ildj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector\u001b[39m.\u001b[39minverse_log_det_jacobian(\n\u001b[0;32m    385\u001b[0m     y, event_ndims\u001b[39m=\u001b[39mevent_ndims, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbijector_kwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\bijector.py:1409\u001b[0m, in \u001b[0;36mBijector.inverse\u001b[1;34m(self, y, name, **kwargs)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse\u001b[39m(\u001b[39mself\u001b[39m, y, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minverse\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1392\u001b[0m   \u001b[39m\"\"\"Returns the inverse `Bijector` evaluation, i.e., X = g^{-1}(Y).\u001b[39;00m\n\u001b[0;32m   1393\u001b[0m \n\u001b[0;32m   1394\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1407\u001b[0m \u001b[39m    NotImplementedError: if `_inverse` is not implemented.\u001b[39;00m\n\u001b[0;32m   1408\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1409\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_inverse(y, name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\bijector.py:1389\u001b[0m, in \u001b[0;36mBijector._call_inverse\u001b[1;34m(self, y, name, **kwargs)\u001b[0m\n\u001b[0;32m   1387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_injective:  \u001b[39m# No caching for non-injective\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inverse(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1389\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39minverse(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\internal\\cache_util.py:351\u001b[0m, in \u001b[0;36mBijectorCache.inverse\u001b[1;34m(self, y, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse\u001b[39m(\u001b[39mself\u001b[39m, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    341\u001b[0m   \u001b[39m\"\"\"Invokes the 'inverse' transformation, or looks up previous results.\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \n\u001b[0;32m    343\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[39m    The output of the bijector's `_inverse` method, or a cached result.\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lookup(y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inverse_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\internal\\cache_util.py:497\u001b[0m, in \u001b[0;36mBijectorCache._lookup\u001b[1;34m(self, input, forward_name, inverse_name, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m   output \u001b[39m=\u001b[39m output_ref()\n\u001b[0;32m    492\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    493\u001b[0m   \u001b[39m# Get the output structure, and declare a\u001b[39;00m\n\u001b[0;32m    494\u001b[0m   \u001b[39m# weakref to clear it from the cache once it gets GCed\u001b[39;00m\n\u001b[0;32m    495\u001b[0m   output \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m    496\u001b[0m       _containerize,\n\u001b[1;32m--> 497\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke(\u001b[39minput\u001b[39;49m, forward_name, kwargs, attrs))\n\u001b[0;32m    498\u001b[0m   output_ref \u001b[39m=\u001b[39m WeakStructRef(\n\u001b[0;32m    499\u001b[0m       output,\n\u001b[0;32m    500\u001b[0m       subkey\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector_class, inverse_name, kwargs),\n\u001b[0;32m    501\u001b[0m       callback\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mmaybe_del)\n\u001b[0;32m    502\u001b[0m   \u001b[39m# Set the input->output mapping.\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\internal\\cache_util.py:536\u001b[0m, in \u001b[0;36mBijectorCache._invoke\u001b[1;34m(self, input, fn_name, kwargs, attributes)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_invoke\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, fn_name, kwargs, attributes):  \u001b[39m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[0;32m    535\u001b[0m   \u001b[39m\"\"\"Invokes the wrapped function. Override to customize behavior.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 536\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector, fn_name)(\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\composition.py:618\u001b[0m, in \u001b[0;36mComposition._inverse\u001b[1;34m(self, y, **kwargs)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_injective:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    615\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    616\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mInvert is not implemented for compositions of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    617\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mnon-injective bijectors.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 618\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_walk_inverse(\n\u001b[0;32m    619\u001b[0m     \u001b[39mlambda\u001b[39;00m b, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: b\u001b[39m.\u001b[39minverse(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs),\n\u001b[0;32m    620\u001b[0m     y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\composition.py:356\u001b[0m, in \u001b[0;36mComposition._call_walk_inverse\u001b[1;34m(self, step_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m args \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(nest_util\u001b[39m.\u001b[39mcoerce_structure(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minverse_min_event_ndims, y)\n\u001b[0;32m    353\u001b[0m              \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m args)\n\u001b[0;32m    355\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 356\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_walk_inverse(step_fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    358\u001b[0m \u001b[39m# Convert a tuple of structures to a structure of tuples. This\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[39m# allows `_walk` methods to route aligned structures of inputs/outputs\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[39m# independently, obviates the need for conditional tuple unpacking.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m packed_args \u001b[39m=\u001b[39m pack_structs_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minverse_min_event_ndims, \u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\chain.py:152\u001b[0m, in \u001b[0;36m_Chain._walk_inverse\u001b[1;34m(self, step_fn, y, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[39m\"\"\"Applies `transform_fn` to `y` sequentially over nested bijectors.\"\"\"\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[39mfor\u001b[39;00m bij \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bijectors:\n\u001b[1;32m--> 152\u001b[0m   y \u001b[39m=\u001b[39m step_fn(bij, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\u001b[39m.\u001b[39mget(bij\u001b[39m.\u001b[39mname, {}))\n\u001b[0;32m    153\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\composition.py:619\u001b[0m, in \u001b[0;36mComposition._inverse.<locals>.<lambda>\u001b[1;34m(b, y, **kwargs)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_injective:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    615\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    616\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mInvert is not implemented for compositions of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    617\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mnon-injective bijectors.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    618\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_walk_inverse(\n\u001b[1;32m--> 619\u001b[0m     \u001b[39mlambda\u001b[39;00m b, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: b\u001b[39m.\u001b[39minverse(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs),\n\u001b[0;32m    620\u001b[0m     y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\bijector.py:1409\u001b[0m, in \u001b[0;36mBijector.inverse\u001b[1;34m(self, y, name, **kwargs)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse\u001b[39m(\u001b[39mself\u001b[39m, y, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minverse\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1392\u001b[0m   \u001b[39m\"\"\"Returns the inverse `Bijector` evaluation, i.e., X = g^{-1}(Y).\u001b[39;00m\n\u001b[0;32m   1393\u001b[0m \n\u001b[0;32m   1394\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1407\u001b[0m \u001b[39m    NotImplementedError: if `_inverse` is not implemented.\u001b[39;00m\n\u001b[0;32m   1408\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1409\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_inverse(y, name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\bijector.py:1389\u001b[0m, in \u001b[0;36mBijector._call_inverse\u001b[1;34m(self, y, name, **kwargs)\u001b[0m\n\u001b[0;32m   1387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_injective:  \u001b[39m# No caching for non-injective\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inverse(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1389\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39minverse(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\internal\\cache_util.py:351\u001b[0m, in \u001b[0;36mBijectorCache.inverse\u001b[1;34m(self, y, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse\u001b[39m(\u001b[39mself\u001b[39m, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    341\u001b[0m   \u001b[39m\"\"\"Invokes the 'inverse' transformation, or looks up previous results.\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \n\u001b[0;32m    343\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[39m    The output of the bijector's `_inverse` method, or a cached result.\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lookup(y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inverse_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\internal\\cache_util.py:497\u001b[0m, in \u001b[0;36mBijectorCache._lookup\u001b[1;34m(self, input, forward_name, inverse_name, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m   output \u001b[39m=\u001b[39m output_ref()\n\u001b[0;32m    492\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    493\u001b[0m   \u001b[39m# Get the output structure, and declare a\u001b[39;00m\n\u001b[0;32m    494\u001b[0m   \u001b[39m# weakref to clear it from the cache once it gets GCed\u001b[39;00m\n\u001b[0;32m    495\u001b[0m   output \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m    496\u001b[0m       _containerize,\n\u001b[1;32m--> 497\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke(\u001b[39minput\u001b[39;49m, forward_name, kwargs, attrs))\n\u001b[0;32m    498\u001b[0m   output_ref \u001b[39m=\u001b[39m WeakStructRef(\n\u001b[0;32m    499\u001b[0m       output,\n\u001b[0;32m    500\u001b[0m       subkey\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector_class, inverse_name, kwargs),\n\u001b[0;32m    501\u001b[0m       callback\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mmaybe_del)\n\u001b[0;32m    502\u001b[0m   \u001b[39m# Set the input->output mapping.\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\internal\\cache_util.py:536\u001b[0m, in \u001b[0;36mBijectorCache._invoke\u001b[1;34m(self, input, fn_name, kwargs, attributes)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_invoke\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, fn_name, kwargs, attributes):  \u001b[39m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[0;32m    535\u001b[0m   \u001b[39m\"\"\"Invokes the wrapped function. Override to customize behavior.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 536\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector, fn_name)(\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\masked_autoregressive.py:386\u001b[0m, in \u001b[0;36mMaskedAutoregressiveFlow._inverse\u001b[1;34m(self, y, **kwargs)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_inverse\u001b[39m(\u001b[39mself\u001b[39m, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 386\u001b[0m   bijector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bijector_fn(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    387\u001b[0m   \u001b[39mreturn\u001b[39;00m bijector\u001b[39m.\u001b[39minverse(y)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\masked_autoregressive.py:315\u001b[0m, in \u001b[0;36mMaskedAutoregressiveFlow.__init__.<locals>._bijector_fn\u001b[1;34m(x, **condition_kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_bijector_fn\u001b[39m(x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcondition_kwargs):\n\u001b[1;32m--> 315\u001b[0m   params \u001b[39m=\u001b[39m shift_and_log_scale_fn(x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcondition_kwargs)\n\u001b[0;32m    316\u001b[0m   \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mis_tensor(params):\n\u001b[0;32m    317\u001b[0m     shift, log_scale \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39munstack(params, num\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1011\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[39m# on symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\n\u001b[0;32m   1009\u001b[0m     \u001b[39mself\u001b[39m, inputs, args, kwargs, input_list\n\u001b[0;32m   1010\u001b[0m ):\n\u001b[1;32m-> 1011\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(\n\u001b[0;32m   1012\u001b[0m         inputs, args, kwargs, input_list\n\u001b[0;32m   1013\u001b[0m     )\n\u001b[0;32m   1015\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:2498\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   2491\u001b[0m         training_arg_passed_by_framework \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[0;32m   2494\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value\n\u001b[0;32m   2495\u001b[0m ):\n\u001b[0;32m   2496\u001b[0m     \u001b[39m# Check input assumptions set after layer building, e.g. input\u001b[39;00m\n\u001b[0;32m   2497\u001b[0m     \u001b[39m# shape.\u001b[39;00m\n\u001b[1;32m-> 2498\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[0;32m   2499\u001b[0m         inputs, input_masks, args, kwargs\n\u001b[0;32m   2500\u001b[0m     )\n\u001b[0;32m   2502\u001b[0m     \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2503\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2504\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2505\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2506\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2507\u001b[0m         )\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:2345\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m   2341\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   2342\u001b[0m         keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature\n\u001b[0;32m   2343\u001b[0m     )\n\u001b[0;32m   2344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(\n\u001b[0;32m   2346\u001b[0m         inputs, args, kwargs, input_masks\n\u001b[0;32m   2347\u001b[0m     )\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:2404\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m   2402\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m   2403\u001b[0m         inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m-> 2404\u001b[0m         outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2406\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[0;32m   2407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(\n\u001b[0;32m   2408\u001b[0m     inputs, outputs, input_masks, build_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   2409\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\masked_autoregressive.py:1136\u001b[0m, in \u001b[0;36mAutoregressiveNetwork.call\u001b[1;34m(self, x, conditional_input)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m   output_shape \u001b[39m=\u001b[39m input_shape\n\u001b[1;32m-> 1136\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mreshape(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network(x),\n\u001b[0;32m   1137\u001b[0m                   tf\u001b[39m.\u001b[39mconcat([output_shape, [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_params]], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    555\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 557\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:510\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    493\u001b[0m     \u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \n\u001b[0;32m    495\u001b[0m \u001b[39m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:667\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    664\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    666\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 667\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mlayer(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    669\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m    671\u001b[0m     node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[0;32m    672\u001b[0m ):\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\keras\\layers\\core\\dense.py:252\u001b[0m, in \u001b[0;36mDense.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    249\u001b[0m         outputs\u001b[39m.\u001b[39mset_shape(output_shape)\n\u001b[0;32m    251\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mbias_add(outputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n\u001b[0;32m    254\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(outputs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:3552\u001b[0m, in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m   3550\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m   3551\u001b[0m   value \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(value, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 3552\u001b[0m   bias \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(bias, dtype\u001b[39m=\u001b[39;49mvalue\u001b[39m.\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbias\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   3554\u001b[0m \u001b[39mreturn\u001b[39;00m gen_nn_ops\u001b[39m.\u001b[39mbias_add(value, bias, data_format\u001b[39m=\u001b[39mdata_format, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1638\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1629\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1630\u001b[0m           _add_error_prefix(\n\u001b[0;32m   1631\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1634\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1635\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[0;32m   1637\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1638\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   1640\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1641\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:2105\u001b[0m, in \u001b[0;36m_dense_var_to_tensor\u001b[1;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   2104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_dense_var_to_tensor\u001b[39m(var, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m-> 2105\u001b[0m   \u001b[39mreturn\u001b[39;00m var\u001b[39m.\u001b[39;49m_dense_var_to_tensor(dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1467\u001b[0m, in \u001b[0;36mBaseResourceVariable._dense_var_to_tensor\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1465\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_value()\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39minputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1466\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1467\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue()\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:582\u001b[0m, in \u001b[0;36mBaseResourceVariable.value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    580\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_value\n\u001b[0;32m    581\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mNone\u001b[39;00m, ignore_existing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 582\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_variable_op()\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:704\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    702\u001b[0m       result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    703\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m   result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    706\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    707\u001b[0m   \u001b[39m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    708\u001b[0m   \u001b[39m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m   tape\u001b[39m.\u001b[39mrecord_operation(\n\u001b[0;32m    710\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadVariableOp\u001b[39m\u001b[39m\"\u001b[39m, [result], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle],\n\u001b[0;32m    711\u001b[0m       backward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    712\u001b[0m       forward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:694\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[39mif\u001b[39;00m no_copy \u001b[39mand\u001b[39;00m forward_compat\u001b[39m.\u001b[39mforward_compatible(\u001b[39m2022\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[0;32m    693\u001b[0m   gen_resource_variable_ops\u001b[39m.\u001b[39mdisable_copy_on_read(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle)\n\u001b[1;32m--> 694\u001b[0m result \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39;49mread_variable_op(\n\u001b[0;32m    695\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype)\n\u001b[0;32m    696\u001b[0m _maybe_set_handle_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, result)\n\u001b[0;32m    697\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:538\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m    537\u001b[0m dtype \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_type(dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 538\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m    539\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mReadVariableOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, resource\u001b[39m=\u001b[39;49mresource, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    540\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m    541\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:735\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    733\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    734\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 735\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    736\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    737\u001b[0m     compute_device)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3800\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3797\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3800\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3801\u001b[0m       node_def,\n\u001b[0;32m   3802\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3803\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3804\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3805\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3806\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3807\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3808\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3809\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3810\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2108\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2105\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   2107\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 2108\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   2109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_c_op(c_op\u001b[39m=\u001b[39mc_op, g\u001b[39m=\u001b[39mg)\n\u001b[0;32m   2111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1966\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1962\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[0;32m   1963\u001b[0m                                          serialized)\n\u001b[0;32m   1965\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1966\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[0;32m   1967\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1968\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1969\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import get_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fair_dummies import fair_dummies_learning\n",
    "from fair_dummies import utility_functions\n",
    "importlib.reload(fair_dummies_learning)\n",
    "importlib.reload(utility_functions)\n",
    "importlib.reload(get_dataset)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "seed = 123\n",
    "for i in range(20):\n",
    "    X, A, Y, X_cal, A_cal, Y_cal, X_test, A_test, Y_test = get_dataset.get_train_test_data(base_path, dataset, seed, dim = 2, specified=\"PctUnemployed\")\n",
    "\n",
    "    specified_density_te = utility_functions.MAF_density_estimation(np.concatenate((Y_cal, Y_test)), np.concatenate((A_cal, A_test)), Y_test, A_test)\n",
    "    ##############\n",
    "    y_perm_index = np.squeeze(utility_functions.generate_X_CPT(50,1000,specified_density_te))\n",
    "    A_perm_index = np.argsort(y_perm_index)\n",
    "    specified_At = A_test[A_perm_index]\n",
    "    ############## \n",
    "    print(\"###################################################\")\n",
    "    model = NetRegression(X.shape[1], 1)\n",
    "\n",
    "    num_epochs = 20\n",
    "    lr = 0.001\n",
    "\n",
    "    # $\\chi^2|_1$\n",
    "    penalty_coefficient = 100\n",
    "    penalty = chi_squared_l1_kde\n",
    "\n",
    "    model = regularized_learning(X, Y, A, model=model, fairness_penalty=penalty, lr=lr, \\\n",
    "                                num_epochs=num_epochs, penalty = penalty_coefficient)\n",
    "\n",
    "    # mse, hgr_infty = evaluate(model, X_test, Y_test, A_test[:,[0]])\n",
    "    Yhat_out_test = model(torch.tensor(X_test.astype(np.float32))).detach().flatten().numpy()\n",
    "    Yhat_out_cal = model(torch.tensor(X_cal.astype(np.float32))).detach().flatten().numpy()\n",
    "    # print(\"MSE:{} HGR_infty:{}\".format(mse, hgr_infty))\n",
    "    print(\"MSE:{}\".format(np.mean((Yhat_out_test - Y_test)**2)))\n",
    "    print(\"Null-MSE:{}\".format(np.mean((np.mean(Y_test) - Y_test)**2)))\n",
    "\n",
    "    p_val = utility_functions.fair_dummies_test_regression(Yhat_out_cal,\n",
    "                                                A_cal,\n",
    "                                                Y_cal,\n",
    "                                                Yhat_out_test,\n",
    "                                                A_test,\n",
    "                                                Y_test,\n",
    "                                                num_reps = 1,\n",
    "                                                num_p_val_rep = 1000,\n",
    "                                                reg_func_name = \"RF\",\n",
    "                                                test_type = \"MAF_CPT_onA\",\n",
    "                                                transform = False,\n",
    "                                                specified_density = specified_density_te,\n",
    "                                                return_vec = True,\n",
    "                                                specified_At = specified_At)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
