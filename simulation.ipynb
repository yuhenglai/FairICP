{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" \n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" \n",
    "base_path = os.getcwd() + '/data/'\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import get_dataset\n",
    "import numpy as np\n",
    "from FairICP import utility_functions\n",
    "from FairICP import FairICP_learning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load R\n",
    "os.environ['R_HOME'] = r\"user\\R\\R-4.3.0\"\n",
    "os.environ['R_USER'] = r\"user\\anaconda3\\Lib\\site-packages\\rpy2\"\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "KPC = importr('KPC')\n",
    "kernlab = importr('kernlab')\n",
    "import rpy2.robjects\n",
    "from rpy2.robjects import FloatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def mix_gamma(n):\n",
    "    # Settings\n",
    "    NumberOfMixtures = 2\n",
    "    # Mixture weights (non-negative, sum to 1)\n",
    "    w = [0.5, 0.5]\n",
    "    # Mean vectors and covariance matrices\n",
    "    shapeVectors = np.array([1, 10])\n",
    "    scaleVectors = np.array([1, 1])\n",
    "    MeanVectors = shapeVectors * scaleVectors\n",
    "    StdVectors = shapeVectors * np.square(scaleVectors)\n",
    "    moments = np.square(MeanVectors) + StdVectors\n",
    "    mean = np.array(w).dot(MeanVectors)\n",
    "    std = np.sqrt(np.array(w).dot(moments) - np.square(mean))\n",
    "    # Initialize arrays\n",
    "    samples = np.zeros(n)\n",
    "    # Generate samples\n",
    "    for iter in range(n):\n",
    "        # Get random number to select the mixture component with probability according to mixture weights\n",
    "        DrawComponent = random.choices(range(NumberOfMixtures), weights=w, cum_weights=None, k=1)[0]\n",
    "        # Draw sample from selected mixture component\n",
    "        DrawSample = np.random.gamma(shape = shapeVectors[DrawComponent], scale = scaleVectors[DrawComponent], size = 1)\n",
    "\n",
    "        DrawSample = (DrawSample - mean) / std\n",
    "        samples[iter] = DrawSample\n",
    "    return samples\n",
    "    \n",
    "def synthetic_example_md(dim_insnst = 5, dim_snst = 1, dim_noisy_a = 0, alpha = 0.5, eps = 1, n = 1000, include_A = False):\n",
    "    # insensitive X\n",
    "    cov_mat = np.full((dim_insnst, dim_insnst), 0)\n",
    "    np.fill_diagonal(cov_mat, 1)\n",
    "    X_insnst = mvn.rvs(mean = [0. for i in range(dim_insnst)], cov=cov_mat, size = n)\n",
    "    if len(X_insnst.shape) == 1: X_insnst = X_insnst[:,None] \n",
    "\n",
    "    # sensitive X\n",
    "    X_snst = np.array([[] for i in range(n)])\n",
    "    A = np.array([[] for i in range(n)])\n",
    "    for i in range(dim_snst):\n",
    "        A_temp = mix_gamma(n)\n",
    "        X_temp = np.sqrt(alpha) * A_temp + np.sqrt(1 - alpha) * np.random.randn(n)\n",
    "        A = np.concatenate([A, A_temp[:,None]], axis = 1)\n",
    "        X_snst = np.concatenate([X_snst, X_temp[:,None]], axis = 1)\n",
    "\n",
    "    # additional A\n",
    "    for i in range(dim_noisy_a):\n",
    "        A_temp = np.random.randn(n)\n",
    "        A = np.concatenate([A, A_temp[:,None]], axis = 1)\n",
    "\n",
    "    X = np.concatenate([X_insnst, X_snst], axis = 1)\n",
    "    beta = [1] * dim_insnst + [1] * dim_snst\n",
    "    Y = np.dot(X, beta) + eps * np.random.randn(n)\n",
    "\n",
    "    if include_A:\n",
    "        X = np.concatenate((X, A), axis = 1)\n",
    "\n",
    "    return X, A, Y\n",
    "\n",
    "def known_prob(Y, A, dim_insnst = 5, alpha = 0.5, eps = 1):\n",
    "    cov_mat = np.full((dim_insnst, dim_insnst), 0)\n",
    "    np.fill_diagonal(cov_mat, 1)\n",
    "    sig_insnst = np.ones(dim_insnst).dot(cov_mat.dot(np.ones(dim_insnst)[:,None]))\n",
    "\n",
    "    sig_snst = A.shape[1] * (1 - alpha)\n",
    "\n",
    "    sig2 = np.full((A.shape[0], ), sig_insnst + sig_snst + np.power(eps, 2))\n",
    "    mu = np.sqrt(alpha) * np.sum(A, axis = 1)\n",
    "\n",
    "    return - np.power(Y,2)[:,None] * (1/2/sig2)[None,:] + Y[:,None] * (mu/sig2)[None,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "simulation_type = 1 # 1/2 for SIM1/SIM2 in the paper \n",
    "\n",
    "if simulation_type == 1:\n",
    "    dim_snst = 10\n",
    "    dim_insnst = dim_snst\n",
    "    dim_noisy_a = 0\n",
    "elif simulation_type == 2:\n",
    "    dim_snst = 1\n",
    "    dim_insnst = dim_snst\n",
    "    dim_noisy_a = 10\n",
    "\n",
    "alpha = 0.9\n",
    "eps = np.sqrt(dim_insnst + dim_snst)\n",
    "\n",
    "X, A, Y = synthetic_example_md(dim_insnst = dim_insnst, dim_snst = dim_snst, dim_noisy_a = dim_noisy_a, alpha = alpha, eps = eps, n = 500)\n",
    "X_test, A_test, Y_test = synthetic_example_md(dim_insnst = dim_insnst, dim_snst = dim_snst, dim_noisy_a = dim_noisy_a, alpha = alpha, eps = eps, n = 400)\n",
    "input_data_train = np.concatenate((A, X), 1)\n",
    "input_data_test = np.concatenate((A_test, X_test), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "lr_loss = 1e-3\n",
    "lr_dis = 1e-4\n",
    "\n",
    "# equalized odds penalty\n",
    "mu_val = 0.9\n",
    "epochs_list = [140]\n",
    "\n",
    "# utility loss\n",
    "cost_pred = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = FairICP_learning.EquiRegLearner(lr_loss = lr_loss,\n",
    "                                            lr_dis = lr_dis,\n",
    "                                            epochs = epochs_list[-1],\n",
    "                                            loss_steps = 1,\n",
    "                                            dis_steps = 1,\n",
    "                                            cost_pred = cost_pred,\n",
    "                                            in_shape = X.shape[1],\n",
    "                                            batch_size = batch_size,\n",
    "                                            model_type = \"linear_model\",\n",
    "                                            lambda_vec = mu_val,\n",
    "                                            out_shape = 1,\n",
    "                                            A_shape = A.shape[1]\n",
    "                                            )\n",
    "model.fit(input_data_train, Y, epochs_list = epochs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate \\tilde A from true permutation\n",
    "log_lik_mat = known_prob(Y_test, A_test[:,:dim_snst], dim_insnst, alpha, eps)\n",
    "\n",
    "y_perm_index = np.squeeze(utility_functions.generate_X_CPT(50, 100, log_lik_mat))\n",
    "A_perm_index = np.argsort(y_perm_index)\n",
    "A_tilde_list = A_test[A_perm_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_trivial: 41.44066956537443\n",
      "mse_model: 20.690114613178263\n",
      "estimated KPC: -0.01357897111950448\n",
      "p-value: 0.31683168316831684\n"
     ]
    }
   ],
   "source": [
    "for i, cp in enumerate(model.checkpoint_list):\n",
    "    model.model = model.cp_model_list[i]\n",
    "    model.dis = model.cp_dis_list[i]\n",
    "\n",
    "    Yhat_out_train = model.predict(input_data_train)\n",
    "    Yhat_out_test = model.predict(input_data_test)\n",
    "\n",
    "    mse_trivial = np.mean((np.mean(Y_test)-Y_test)**2)\n",
    "    mse_model = np.mean((Yhat_out_test-Y_test)**2)\n",
    "    print(f\"mse_trivial: {mse_trivial}\")\n",
    "    print(f\"mse_model: {mse_model}\")\n",
    "\n",
    "    rYhat = FloatVector(Yhat_out_test)  \n",
    "    rZ = rpy2.robjects.r.matrix(FloatVector(A_test[:,:dim_snst].T.flatten()), nrow=A_test[:,:dim_snst].shape[0], ncol=A_test[:,:dim_snst].shape[1]) \n",
    "    rY = rpy2.robjects.r.matrix(FloatVector(Y_test), nrow=A_test[:,:dim_snst].shape[0], ncol=1)\n",
    "    \n",
    "    stat = KPC.KPCgraph \n",
    "    res_ = stat(Y = rYhat, X = rY, Z = rZ, Knn = \"MST\")[0]\n",
    "    print(f\"estimated KPC: {res_}\")\n",
    "    res_list = np.zeros(100)\n",
    "    for i in range(100):\n",
    "        At_test = A_tilde_list[i]\n",
    "        rZt = rpy2.robjects.r.matrix(FloatVector(At_test[:,:dim_snst].T.flatten()), nrow=A_test[:,:dim_snst].shape[0], ncol=A_test[:,:dim_snst].shape[1])\n",
    "        res_list[i] = stat(Y = rYhat, X = rY, Z = rZt, Knn = \"MST\")[0]\n",
    "    p_val = 1.0/(100+1) * (1 + sum(res_list >= res_))\n",
    "    print(f\"p-value: {p_val}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
